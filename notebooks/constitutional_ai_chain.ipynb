{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "769117af-78ea-4d37-8a6c-b63dcd38a928",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Chain for applying constitutional principles to the outputs of another chain.\"\"\"\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
    "from langchain.chains.constitutional_ai.principles import PRINCIPLES\n",
    "from langchain.chains.constitutional_ai.prompts import CRITIQUE_PROMPT, REVISION_PROMPT\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.schema import BasePromptTemplate\n",
    "from langchain.schema.language_model import BaseLanguageModel\n",
    "\n",
    "\n",
    "class ConstitutionalChain(Chain):\n",
    "    \"\"\"Chain for applying constitutional principles.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "\n",
    "            from langchain.llms import OpenAI\n",
    "            from langchain.chains import LLMChain, ConstitutionalChain\n",
    "            from langchain.chains.constitutional_ai.models \\\n",
    "                import ConstitutionalPrinciple\n",
    "\n",
    "            llm = OpenAI()\n",
    "\n",
    "            qa_prompt = PromptTemplate(\n",
    "                template=\"Q: {question} A:\",\n",
    "                input_variables=[\"question\"],\n",
    "            )\n",
    "            qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
    "\n",
    "            constitutional_chain = ConstitutionalChain.from_llm(\n",
    "                llm=llm,\n",
    "                chain=qa_chain,\n",
    "                constitutional_principles=[\n",
    "                    ConstitutionalPrinciple(\n",
    "                        critique_request=\"Tell if this answer is good.\",\n",
    "                        revision_request=\"Give a better answer.\",\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            constitutional_chain.run(question=\"What is the meaning of life?\")\n",
    "    \"\"\"\n",
    "\n",
    "    chain: Chain\n",
    "    constitutional_principles: List[ConstitutionalPrinciple]\n",
    "    critique_chain: Chain\n",
    "    revision_chain: Chain\n",
    "    return_intermediate_steps: bool = False\n",
    "\n",
    "    @classmethod\n",
    "    def get_principles(\n",
    "        cls, names: Optional[List[str]] = None\n",
    "    ) -> List[ConstitutionalPrinciple]:\n",
    "        if names is None:\n",
    "            return list(PRINCIPLES.values())\n",
    "        else:\n",
    "            return [PRINCIPLES[name] for name in names]\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls,\n",
    "        llm: BaseLanguageModel,\n",
    "        chain: LLMChain,\n",
    "        critique_prompt: BasePromptTemplate = CRITIQUE_PROMPT,\n",
    "        revision_prompt: BasePromptTemplate = REVISION_PROMPT,\n",
    "        **kwargs: Any,\n",
    "    ) -> \"ConstitutionalChain\":\n",
    "        \"\"\"Create a chain from an LLM.\"\"\"\n",
    "        critique_chain = LLMChain(llm=llm, prompt=critique_prompt)\n",
    "        revision_chain = LLMChain(llm=llm, prompt=revision_prompt)\n",
    "        return cls(\n",
    "            chain=chain,\n",
    "            critique_chain=critique_chain,\n",
    "            revision_chain=revision_chain,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        \"\"\"Input keys.\"\"\"\n",
    "        return self.chain.input_keys\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        \"\"\"Output keys.\"\"\"\n",
    "        if self.return_intermediate_steps:\n",
    "            return [\"output\", \"critiques_and_revisions\", \"initial_output\"]\n",
    "        return [\"output\"]\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
    "        response = self.chain.run(\n",
    "            **inputs,\n",
    "            callbacks=_run_manager.get_child(\"original\"),\n",
    "        )\n",
    "        initial_response = response\n",
    "        input_prompt = self.chain.prompt.format(**inputs)\n",
    "\n",
    "        _run_manager.on_text(\n",
    "            text=\"Initial response: \" + response + \"\\n\\n\",\n",
    "            verbose=self.verbose,\n",
    "            color=\"yellow\",\n",
    "        )\n",
    "        critiques_and_revisions = []\n",
    "        for constitutional_principle in self.constitutional_principles:\n",
    "            # Do critique\n",
    "\n",
    "            raw_critique = self.critique_chain.run(\n",
    "                input_prompt=input_prompt,\n",
    "                output_from_model=response,\n",
    "                critique_request=constitutional_principle.critique_request,\n",
    "                callbacks=_run_manager.get_child(\"critique\"),\n",
    "            )\n",
    "            critique = self._parse_critique(\n",
    "                output_string=raw_critique,\n",
    "            ).strip()\n",
    "\n",
    "            # if the critique contains \"No critique needed\", then we're done\n",
    "            # in this case, initial_output is the same as output,\n",
    "            # but we'll keep it for consistency\n",
    "            if \"no critique needed\" in critique.lower():\n",
    "                critiques_and_revisions.append((critique, \"\"))\n",
    "                continue\n",
    "\n",
    "            # Do revision\n",
    "\n",
    "            revision = self.revision_chain.run(\n",
    "                input_prompt=input_prompt,\n",
    "                output_from_model=response,\n",
    "                critique_request=constitutional_principle.critique_request,\n",
    "                critique=critique,\n",
    "                revision_request=constitutional_principle.revision_request,\n",
    "                callbacks=_run_manager.get_child(\"revision\"),\n",
    "            ).strip()\n",
    "            response = revision\n",
    "            critiques_and_revisions.append((critique, revision))\n",
    "\n",
    "            _run_manager.on_text(\n",
    "                text=f\"Applying {constitutional_principle.name}...\" + \"\\n\\n\",\n",
    "                verbose=self.verbose,\n",
    "                color=\"green\",\n",
    "            )\n",
    "\n",
    "            _run_manager.on_text(\n",
    "                text=\"Critique: \" + critique + \"\\n\\n\",\n",
    "                verbose=self.verbose,\n",
    "                color=\"blue\",\n",
    "            )\n",
    "\n",
    "            _run_manager.on_text(\n",
    "                text=\"Updated response: \" + revision + \"\\n\\n\",\n",
    "                verbose=self.verbose,\n",
    "                color=\"yellow\",\n",
    "            )\n",
    "\n",
    "        final_output: Dict[str, Any] = {\"output\": response}\n",
    "        if self.return_intermediate_steps:\n",
    "            final_output[\"initial_output\"] = initial_response\n",
    "            final_output[\"critiques_and_revisions\"] = critiques_and_revisions\n",
    "        return final_output\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_critique(output_string: str) -> str:\n",
    "        if \"Revision request:\" not in output_string:\n",
    "            return output_string\n",
    "        output_string = output_string.split(\"Revision request:\")[0]\n",
    "        if \"\\n\\n\" in output_string:\n",
    "            output_string = output_string.split(\"\\n\\n\")[0]\n",
    "        return output_string\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "constitutional_ai_chain",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
